# Experiment config, this overwrites the defaults.

output:

  # Path for the main output directory
  output_dir: ./outputs

  # Add extra text to the output folder. No deactivates it
  extra_text: no

  # Enable logging with tensorboard
  tensorbord: yes

  # Enable printing
  verbose: yes

  # Redirects stdout to file output.txt
  to_file: no

optimization:

  # Input batch size for training and validation
  batch_size: 100

  # Number of epochs for training
  epochs: 2000

  # learning rate
  lr: 0.0003

  # Grace period for early stopping
  grace_early_stopping: 50

  # Number of warmup epochs
  warmup: 200

experiment:

  # Size of the latent space
  latent_size: 50

  # Type of VAE to use
  # Possible options: standard, copula, diagonal, copulaV2
  type_vae: copula

  # Type of architecture ot be used.
  # Possible options: shallow, deep, conv
  architecture: shallow

  # Type of marginals that should we used in the architecture. It is ignored if not required
  # Possible options: gaussian, laplace, log_norm, cauchy, exp'
  marginals: gaussian

  # Number of samples used for approximating the log-likelihood
  samples_ll: 5

dataset:

  # Name of the database to load
  # Possible options: binary_mnist, mnist, bedrooms, omniglot, cifar10, fashionmnist, dSprites
  dataset_name: mnist

  # Allow dynamic binarization. Ignored if it does not make sense
  dynamic_binarization: yes

  # Shuffle the dataset
  shuffle: no

checkpointing:

  # Every how many epochs do I checkpoint
  # 0 means that we checkpoint every 5% of number of epochs
  # This is ignored if checkpointing is false
  frequency_checkpoints: 0
